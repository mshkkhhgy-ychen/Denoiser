# Training configuration
GPU: [0,1,2,3]

VERBOSE: False

SWINUNET:
  IMG_SIZE: 256
  PATCH_SIZE: 4
  WIN_SIZE: 8
  EMB_DIM: 96
  DEPTH_EN: [8, 8, 8, 8]
  HEAD_NUM: [8, 8, 8, 8]
  MLP_RATIO: 4.0
  QKV_BIAS: True
  QK_SCALE: 8
  DROP_RATE: 0.
  ATTN_DROP_RATE: 0.
  DROP_PATH_RATE: 0.1
  APE: False
  PATCH_NORM: True
  USE_CHECKPOINTS: False
  FINAL_UPSAMPLE: 'Dual up-sample'
  # Parameters for Context Blocks
  CONTEXT_RATIO: 0.25                    # Equivalent to 1/16
  CONTEXT_POOLING_TYPE: 'att'              # Attention pooling
  CONTEXT_FUSION_TYPES: ['channel_mul', 'channel_add']    # Fusion type

  # Parameters for Cross-Attention Layers
  CROSS_ATTN_TYPE: 'CrossAttentionWithPositionalEncoding'  # Type of cross-attention layer

MODEL:
  MODE: 'Denoising'

# Optimization arguments.
OPTIM:
  BATCH: 4
  EPOCHS: 150
  # EPOCH_DECAY: [10]
  LR_INITIAL: 2e-4
  LR_MIN: 1e-6
  # BETA1: 0.9

TRAINING:
  VAL_AFTER_EVERY: 1
  RESUME: False
  TRAIN_PS: 256
  VAL_PS: 256
  TRAIN_DIR: './datasets/Denoising_DIV2K/train'       # path to training data
  VAL_DIR: './datasets/Denoising_DIV2K/test' # path to validation data
  SAVE_DIR: './checkpoints/CrossAttentionWithPositionalEncoding_channelmuladd_tune/'           # path to save models and images
